{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XAWDGz4rIbR"
   },
   "outputs": [],
   "source": [
    "%pycat /usr/local/lib/python3.6/dist-packages/keras_vggface/models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5mn1uwt4qPvs",
    "outputId": "bdac1624-5826-4347-857c-a34196aa8b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /usr/local/lib/python3.6/dist-packages/keras_vggface/models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /usr/local/lib/python3.6/dist-packages/keras_vggface/models.py\n",
    "from keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D, \\\n",
    "    GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
    "    AveragePooling2D, Reshape, Permute, multiply\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras_vggface import utils\n",
    "from keras.engine.topology import get_source_inputs\n",
    "import warnings\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights='vggface',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=2622):\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(\n",
    "        img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(\n",
    "        x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(\n",
    "        x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(\n",
    "        x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(\n",
    "        x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(\n",
    "        x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(\n",
    "        x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(\n",
    "        x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(\n",
    "        x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(\n",
    "        x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(\n",
    "        x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(\n",
    "        x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, name='fc6')(x)\n",
    "        x = Activation('relu', name='fc6/relu')(x)\n",
    "        x = Dense(4096, name='fc7')(x)\n",
    "        x = Activation('relu', name='fc7/relu')(x)\n",
    "        x = Dense(classes, name='fc8')(x)\n",
    "        x = Activation('softmax', name='fc8/softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "            # Ensure that the model takes into account\n",
    "            # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "        # Create model.\n",
    "    model = Model(inputs, x, name='vggface_vgg16')  # load weights\n",
    "    if weights == 'vggface':\n",
    "        if include_top:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_vgg16.h5',\n",
    "                                    utils.\n",
    "                                    VGG16_WEIGHTS_PATH,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        else:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_notop_vgg16.h5',\n",
    "                                    utils.VGG16_WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='pool5')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc6')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape,\n",
    "                                                              'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_identity_block(input_tensor, kernel_size, filters, stage, block,\n",
    "                          bias=False):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
    "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_increase\"\n",
    "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), use_bias=bias, name=conv1_reduce_name)(\n",
    "        input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, use_bias=bias,\n",
    "               padding='same', name=conv3_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), use_bias=bias, name=conv1_increase_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_conv_block(input_tensor, kernel_size, filters, stage, block,\n",
    "                      strides=(2, 2), bias=False):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
    "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_increase\"\n",
    "    conv1_proj_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_proj\"\n",
    "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides, use_bias=bias,\n",
    "               name=conv1_reduce_name)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same', use_bias=bias,\n",
    "               name=conv3_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides, use_bias=bias,\n",
    "                      name=conv1_proj_name)(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=conv1_proj_name + \"/bn\")(\n",
    "        shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def RESNET50(include_top=True, weights='vggface',\n",
    "             input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=8631):\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=197,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (7, 7), use_bias=False, strides=(2, 2), padding='same',\n",
    "        name='conv1/7x7_s2')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='conv1/7x7_s2/bn')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = resnet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
    "    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
    "    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
    "\n",
    "    x = resnet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
    "    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
    "    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
    "    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
    "\n",
    "    x = resnet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
    "\n",
    "    x = resnet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
    "    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
    "    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
    "\n",
    "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, activation='softmax', name='classifier')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vggface_resnet50')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'vggface':\n",
    "        if include_top:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_resnet50.h5',\n",
    "                                    utils.RESNET50_WEIGHTS_PATH,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        else:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_notop_resnet50.h5',\n",
    "                                    utils.RESNET50_WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='avg_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='classifier')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape,\n",
    "                                                              'channels_first')\n",
    "\n",
    "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
    "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                          'are using the Theano '\n",
    "                          'image data format convention '\n",
    "                          '(`image_data_format=\"channels_first\"`). '\n",
    "                          'For best performance, set '\n",
    "                          '`image_data_format=\"channels_last\"` in '\n",
    "                          'your Keras config '\n",
    "                          'at ~/.keras/keras.json.')\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def senet_se_block(input_tensor, stage, block, compress_rate=16, bias=False):\n",
    "    conv1_down_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_down\"\n",
    "    conv1_up_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_up\"\n",
    "\n",
    "    num_channels = int(input_tensor.shape[-1])\n",
    "    bottle_neck = int(num_channels // compress_rate)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Reshape((1, 1, num_channels))(se)\n",
    "    se = Conv2D(bottle_neck, (1, 1), use_bias=bias,\n",
    "                name=conv1_down_name)(se)\n",
    "    se = Activation('relu')(se)\n",
    "    se = Conv2D(num_channels, (1, 1), use_bias=bias,\n",
    "                name=conv1_up_name)(se)\n",
    "    se = Activation('sigmoid')(se)\n",
    "\n",
    "    x = input_tensor\n",
    "    x = multiply([x, se])\n",
    "    return x\n",
    "\n",
    "\n",
    "def senet_conv_block(input_tensor, kernel_size, filters,\n",
    "                     stage, block, bias=False, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
    "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_increase\"\n",
    "    conv1_proj_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_proj\"\n",
    "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), use_bias=bias, strides=strides,\n",
    "               name=conv1_reduce_name)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same', use_bias=bias,\n",
    "               name=conv3_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
    "\n",
    "    se = senet_se_block(x, stage=stage, block=block, bias=True)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), use_bias=bias, strides=strides,\n",
    "                      name=conv1_proj_name)(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis,\n",
    "                                  name=conv1_proj_name + \"/bn\")(shortcut)\n",
    "\n",
    "    m = layers.add([se, shortcut])\n",
    "    m = Activation('relu')(m)\n",
    "    return m\n",
    "\n",
    "\n",
    "def senet_identity_block(input_tensor, kernel_size,\n",
    "                         filters, stage, block, bias=False):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
    "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_increase\"\n",
    "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), use_bias=bias,\n",
    "               name=conv1_reduce_name)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same', use_bias=bias,\n",
    "               name=conv3_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
    "\n",
    "    se = senet_se_block(x, stage=stage, block=block, bias=True)\n",
    "\n",
    "    m = layers.add([x, se])\n",
    "    m = Activation('relu')(m)\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def SENET50(include_top=True, weights='vggface',\n",
    "            input_tensor=None, input_shape=None,\n",
    "            pooling=None,\n",
    "            classes=8631):\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=197,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (7, 7), use_bias=False, strides=(2, 2), padding='same',\n",
    "        name='conv1/7x7_s2')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='conv1/7x7_s2/bn')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = senet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
    "    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
    "    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
    "\n",
    "    x = senet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
    "    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
    "    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
    "    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
    "\n",
    "    x = senet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
    "\n",
    "    x = senet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
    "    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
    "    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
    "\n",
    "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, activation='softmax', name='classifier')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vggface_senet50')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'vggface':\n",
    "        if include_top:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_senet50.h5',\n",
    "                                    utils.SENET50_WEIGHTS_PATH,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        else:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_notop_senet50.h5',\n",
    "                                    utils.SENET50_WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='avg_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='classifier')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape,\n",
    "                                                              'channels_first')\n",
    "\n",
    "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
    "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                          'are using the Theano '\n",
    "                          'image data format convention '\n",
    "                          '(`image_data_format=\"channels_first\"`). '\n",
    "                          'For best performance, set '\n",
    "                          '`image_data_format=\"channels_last\"` in '\n",
    "                          'your Keras config '\n",
    "                          'at ~/.keras/keras.json.')\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPEiTOldqDQV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sE6Xpglspzy"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense, Input, Reshape, Lambda, RepeatVector\n",
    "from keras.models import Model\n",
    "from tensorflow.image import resize_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9w8WgBwi76nB"
   },
   "outputs": [],
   "source": [
    "img_inputs = Input(shape=(48*48,))\n",
    "img_rep = RepeatVector(3)(img_inputs)\n",
    "img_reshape = Reshape([48,48,3])(img_rep)\n",
    "img_resized = Lambda(lambda x : resize_images(x,[224,224],\n",
    "    align_corners = True, # possibly important\n",
    "    preserve_aspect_ratio = True))(img_reshape)\n",
    "resize_model = Model(inputs=img_inputs, outputs=img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 3, 2304)           0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 224, 224, 3)       0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resize_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IC_V_l_zqMc0"
   },
   "outputs": [],
   "source": [
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "vgg_model = VGGFace(include_top=False, input_shape=(224, 224, 3))\n",
    "last_layer = vgg_model.get_layer('pool3').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
    "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "custom_vgg_model = Model(vgg_model.input, out)\n",
    "final_model = Model(inputs = resize_model.input, outputs = custom_vgg_model(resize_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_1/resize_images/Squeeze:0' shape=(?, ?, 2304) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9w8WgBwi76nB"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_rep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0102da3e1592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m img_resized = Lambda(lambda x : resize_images(x,[224,224],\n\u001b[1;32m      4\u001b[0m     \u001b[0malign_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# possibly important\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     preserve_aspect_ratio = True))(img_rep)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mresize_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_rep' is not defined"
     ]
    }
   ],
   "source": [
    "img_inputs = Input(shape=(48*48*3,))\n",
    "img_reshape = Reshape([48,48,3])(img_inputs)\n",
    "img_resized = Lambda(lambda x : resize_images(x,[224,224],\n",
    "    align_corners = True, # possibly important\n",
    "    preserve_aspect_ratio = True))(img_rep)\n",
    "resize_model = Model(inputs=img_inputs, outputs=img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dd6c97095f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_vgg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m    719\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                             output_tensors = to_list(\n\u001b[0;32m--> 721\u001b[0;31m                                 layer.call(computed_tensor, **kwargs))\n\u001b[0m\u001b[1;32m    722\u001b[0m                             output_masks = layer.compute_mask(computed_tensor,\n\u001b[1;32m    723\u001b[0m                                                               computed_mask)\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3648\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3649\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3650\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         data_format=data_format)\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0minput_channels_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_spatial_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mspatial_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_spatial_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "final_model = Model(inputs = resize_model.input, outputs = custom_vgg_model(resize_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run simplest_v1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T53LtOKhtaGi"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "agaIGiswuSDN"
   },
   "outputs": [],
   "source": [
    "labels = np.vstack((train_images_label, 1-train_images_label)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1033
    },
    "colab_type": "code",
    "id": "i--CrNVytZKB",
    "outputId": "758bb02c-3774-49ea-f163-5f5460fe3f01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "final_model.compile('adam', 'binary_crossentropy')\n",
    "final_model.fit(data, label, validation_split=0.1, batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ctKIoQJ3ttWL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images_data.reshape((-1,56,56,3))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRWywM9E2ZkM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46tZzZOusf4g"
   },
   "outputs": [],
   "source": [
    "train_images_fname = 'db_train.raw'\n",
    "train_labels_fname = 'label_2019_train.txt'\n",
    "\n",
    "val_images_fname    = 'db_val.raw'\n",
    "\n",
    "\n",
    "# number of images\n",
    "num_train_images = 116157\n",
    "num_valid_images = 27013\n",
    "\n",
    "\n",
    "# size of the images 56*56 pixels in gray levels\n",
    "image_dim = 56 * 56 * 3\n",
    "\n",
    "train_images_label = np.loadtxt(train_labels_fname, dtype=np.float64)\n",
    "\n",
    "with open(train_images_fname, 'rb') as f:\n",
    "    train_images_data = np.fromfile(f, dtype=np.uint8, count=num_train_images * image_dim)\n",
    "    train_images_data = train_images_data.reshape(num_train_images, image_dim)\n",
    "    \n",
    "with open(val_images_fname, 'rb') as f:\n",
    "    val_images_data = np.fromfile(f, dtype=np.uint8, count=num_valid_images * image_dim)\n",
    "    val_images_data = val_images_data.reshape(num_valid_images, image_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
