{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>MDI343 / MDI724 - TP1 Avazu<center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First name : ... fill in your first name ...\n",
    "## Last name : ... fill in your last name ...\n",
    "## Email : ... fill in your email ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 0:**\n",
    "    Import the needed packages: numpy, pandas etc..\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 1:**\n",
    "    Load the data into a pandas DataFrame and display the first lines with the \".head()\" method.\n",
    "    <br>\n",
    "</font>\n",
    "**Remark**: the features meaning is available at https://www.kaggle.com/c/avazu-ctr-prediction/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path_to_the_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 2:**\n",
    "    What is the 'click' frequency in the dataset?\n",
    "    <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the Avazu dataset is very unbalanced. The 'click' class represents less than a fifth of the whole database. We already know that a classifier always predicting 'click'=0 will have good preformances in terms of error rate (around 0.17). The ROC and lift curves will be better performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 3:**\n",
    "    What are the categorical features? Using the 'df.dtypes' method, compute the number of distincts values for each of these features.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 4:**\n",
    "    If one does a dummy encoding of all categorical variables, what would be the dimension of the model?\n",
    "    In other words: what would be the dimension of our big feature vector encoded with dummies. \n",
    "    <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 5:**\n",
    "    Analyze the 'hour' column: which format is used? How can we transform/simply this feature?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[ ... ].head()) # Fill here\n",
    "print(df[ ... ].tail()) # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 6:**\n",
    "    Run and understand the following script.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def datesplit(originalDate):\n",
    "    originalDate = str(originalDate)\n",
    "    \n",
    "    year = int(\"20\" + originalDate[0:2])\n",
    "    month = int(originalDate[2:4])\n",
    "    day = int(originalDate[4:6])\n",
    "    hour = int(originalDate[6:8])\n",
    "    \n",
    "    return datetime.datetime(year, month, day, hour)\n",
    "\n",
    "# Exemple :\n",
    "datesplit(14102915).weekday(), datesplit(14102915).hour"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comments here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 7:**\n",
    "    Using the \".apply( ... )\" method, create a 'weekday' for the day of the week. Then, replace the 'hour' column by the hour.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question you have to understand that applies takes a function as argument\n",
    "<br>\n",
    "\"lambda x: ... \" is used to create local unamed function of x\n",
    "<br>\n",
    "Check the documentation: https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = ... # Fill here\n",
    "df['hour'] = ... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 8:**\n",
    "    Using the \".groupby( ... )\" method, visualize the influence of the hour and of the day on the 'click' frequency. To do so, plot 'click' vs 'hour' and 'click' vs 'weekday' curves.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby( ... )[ ... ]) # Fill here for the influence of the hour\n",
    "print(df.groupby( ... )[ ... ]) # Fill here for the influence of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here for the influence of the hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here for the influence of the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 9:**\n",
    "    Explain what the axes stand for and try to interpret the shape of the obtained curves.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comments here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary work and first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by understanding the features with few modalities:\n",
    "'hour', 'weekday', 'C1', 'banner_pos', 'site_category', 'app_category', 'device_type', 'device_conn_type', 'C15', 'C16', 'C18', 'C21'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 10:**\n",
    "    For instance, inspect the columns 'C15' (dimension of the advert) and 'site_category': visualize the clicks mean.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here: inspect 'C15' using '.groupby'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here: inspect 'site_category' using '.groupby'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 11:**\n",
    "    Some site categories have a null click rate. Why? Display the 'count()' of each modality.\n",
    "    <br><br>\n",
    "    Hint: you can use the method \".value_counts()\"\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comments here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is practical to visualize both columns in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'C1'\n",
    "a = pd.DataFrame([df.groupby(col).mean()['click'], df.groupby(col).count()['click']]).transpose()\n",
    "a.columns = ['mean', 'count']\n",
    "a.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 12:**\n",
    "    Divide the dataset into a training (90%) and test set (10%) with sklearn (use the following option: random_state=100).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ...\n",
    "Xtrain, Xtest, ytrain, ytest = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First work on a reduced number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 13:**\n",
    "    Put in a list the selected columns: 'hour', 'weekday', 'C1', 'banner_pos', 'site_category', 'app_category', 'device_type', 'device_conn_type', 'C15', 'C16', 'C18', 'C21'.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_columns = ['hour', 'weekday', 'C1', 'banner_pos', 'site_category', 'app_category', \n",
    "                'device_type', 'device_conn_type', 'C15', 'C16', 'C18', 'C21']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 14:**\n",
    "    <br>\n",
    "    - Import OneHotEncoder from sklearn.preprocessing\n",
    "    <br>\n",
    "    - Transform the training and the test data restricted to the selected columns\n",
    "    <br>\n",
    "    - Give the type of the outputs.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import ...\n",
    "ohe = OneHotEncoder()\n",
    "Xtrain_oh = ... # fit the transformation of Xtrain restricted to selected columns\n",
    "Xtest_oh = ... # and transform Xtest restricted to selected columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comments here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 15:**\n",
    "    What is the new number of features?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 16:**\n",
    "    Visualize the first row of the design matrix you have got.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 17:**\n",
    "    Import and fit a logistic regression model on your the encoded data\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ...\n",
    "lr = ...\n",
    "lr.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 18:**\n",
    "    With '.predict' and 'predict_proba', display the hard and soft decision you get on test data.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard = ...\n",
    "soft = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 19:**\n",
    "    Compute the probability of **error** using sklearn.metrics 'accuracy_score' function. Comment.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "... # Fill here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 20:**\n",
    "    Which sklearn.metrics could you also use?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 21:**\n",
    "    Plot the ROC curve. Then compute the log loss and the Area Under the Curve ROC.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "... # Fill here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ... , ... \n",
    "log_loss( ... ), roc_auc_score( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 22:**\n",
    "    <br>\n",
    "    - Import the 'plot_lift' function from 'utils.py' and plot the lift curve. What is the lift of the first fifth of the population identified by the test?\n",
    "    <br>\n",
    "    -  Interpret it. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plotlift\n",
    "plotlift( ... )\n",
    "# The following line just plots a vertical line for you to answer the second part of the question\n",
    "plt.axvline(x= ... , linestyle='--', color='r') # Fill here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we now work on the 'site_id' column.\n",
    "<font color=\"red\">**Question 23:**\n",
    "    <br>\n",
    "    - For each modality, compute the number of occurrences in the dataset and the average of clicks for this modality \n",
    "    <br>\n",
    "    - With 'sns.joiplot', represent the set of points (count, mean) for each modality\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'site_id'\n",
    "a = pd.DataFrame([df.groupby(col).mean()['click'], df.groupby(col).count()['click']]).transpose()\n",
    "a.columns = ['mean', 'n_val']\n",
    "sns.jointplot(a['n_val'], a['mean'], alpha=0.25);\n",
    "thres = 10000\n",
    "sns.jointplot(a[a['n_val']<thres]['n_val'], a[a['n_val']<thres]['mean'], alpha=0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 24:**\n",
    "    In the above commands, what does the alpha parameter stand for?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several sites with a lot of occurrences in the dataset have a click frequency very different from the mean. It is relevant to keep the column 'site_id' at least for the modalities for which 'count' is very high.\n",
    "<font color=\"red\">**Question 25:**\n",
    "    Do the same work on the 'device_id' column. What do you notice? What could be the isolated point?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ... # Fill here\n",
    "a = pd.DataFrame([df.groupby(col).mean()['click'], df.groupby(col).count()['click']]).transpose()\n",
    "a.columns = ['mean', 'n_val']\n",
    "sns.jointplot(a['n_val'], a['mean'], alpha=0.25);\n",
    "thres = 10000\n",
    "sns.jointplot(a[a['n_val']<thres]['n_val'], a[a['n_val']<thres]['mean'], alpha=0.25);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 26**:   \n",
    "    In the column df['device_id'], spot the value V corresponding to the largest number of 'count' (using '.value_counts' method). Create a new column df['user'] defined as follows:\n",
    "</font>\n",
    "$$\n",
    "\\text{user} = \\left\\{\\begin{array}[h]{ll} \\text{device_ip + device_model} & \\text{if device_id = V}\\\\ \\text{device_id} & \\text{else.}\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = ... # Fill here\n",
    "...\n",
    "df['user'] = ... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 27**:\n",
    "    Drop the following columns: 'device_id','device_model','device_ip'\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 28**:\n",
    "    One could look at the similarity between 'site_id' and 'site_domain'. Merge those columns into a new 'site' column and delete the old 'site_id' and 'site_domain' columns.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 29**:\n",
    "    Once again, split the modified DataFrame df into a train (90%) and a test set (10%) (with option: random_state = 100).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 30**:\n",
    "    Define a OneHotEncoder and then, 'fit_transform' the train set.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "Xtrain_oh = ... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 31**:\n",
    "    Transform the test set. If an error occurs, analyze it and try to solve it. Which argument did you set ?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_oh = ... # Fill here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 32**:\n",
    "    What is the new number of features?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 33**:\n",
    "    How many modalities have been seen more than a 100 times?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following 'n_ones' vector below gives the number of '1' in each column/modality of the Xtrain_oh design matrix.\n",
    "n_ones = np.array(Xtrain_oh.sum(...))\n",
    "... # Fill here using 'n_ones'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list 'cols_to_keep' below is used to store the indices of the modalities seen more than a 100 times. You can notice the use of the 'enumerate' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful = ... # Fill here.\n",
    "cols_to_keep = ... # Fill here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 34**:\n",
    "    Using only our restriction on the 'cols_to_keep' columns, retrain a logistic regression model and compare its performance in terms of 'log_loss' and 'roc_auc_curve'.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... #Fill here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 35**:\n",
    "    <br>\n",
    "    - Import GradientBoostingClassifier from scikit learn. \n",
    "    <br>\n",
    "    - Initialize it using 50 estimators and a learning rate of 0.8. Set 'verbose=True' to monitor the progress of the algorithm.\n",
    "    <br>\n",
    "    - Fit it on the same columns 'cols_to_keep' of Xtrain_oh than for the previous logistic regression.\n",
    "    <br>\n",
    "    - Evaluate its performance as in the previous step.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ...\n",
    "gb = ... # Fill here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = ...\n",
    "log_loss(...), roc_auc_score(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 36**:\n",
    "    What does the 'gb.estimators_' output?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try to use the 'gb' classifier to generate features that will be relevant inputs for the logistic regression.\n",
    "<font color=\"red\">**Question 37**:\n",
    "    With the 'gb.apply()' method, generate a transformation 'leafs_train' of the training set 'Xtrain_oh[:, cols_to_keep]' for which the nth column corresponds to the number of the leaf returned by the estimator n.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After your applied gb.apply on Xtrain_oh[:, cols_to_keep], remember that use have only one class to predict (click = 0 or 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leafs_train = pd.DataFrame( ... ) # Fill here\n",
    "leafs_test = pd.DataFrame( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 38**:\n",
    "    Encode these new features into dummies.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder( ... ) # Fill here an argument if needed\n",
    "leafs_train_oh = ...\n",
    "leafs_test_oh = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 39**:\n",
    "    With the \"hstack\" function, create a new matrix of features by concatenating horizontally our new features \"leafs_train_oh\" and \"leafs_test_oh\", and previous features used for logistic regression (e.g. in \"Xtrain_oh[:, cols_to_keep]\").\n",
    "</font>\n",
    "<br><br>\n",
    "**Remark**: we use \"hstack\" from scipy.sparse (and not from numpy) because the output of our OneHotEncoder is a sparse array. You can verify it with the command \"type(Xtrain_oh)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "Xtrain_concat = hstack([ ... , ... ]) # Fill here\n",
    "Xtest_concat = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 40**:\n",
    "    Run a logistic regression on the new features and evaluate its performance as before.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 41**:\n",
    "    <br>\n",
    "    - Import XGBClassifier from xgboost package.\n",
    "    <br>\n",
    "    - Initialize it using the same number of estimators and learning rate as before. \n",
    "    <br>\n",
    "    - Which value of n_jobs did you choose?\n",
    "    <br>\n",
    "    - Fit it on the same columns 'cols_to_keep' of Xtrain_oh than for the previous logistic regression.\n",
    "    <br>\n",
    "    - Evaluate its performance and compare it to the GradientBoosting classifier of scikit learn. How is the error? Does it take more time to run?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import ...\n",
    "xgb = XGBClassifier( ... , ... , ... )\n",
    "%time xgb.fit( ... )\n",
    "..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 42**:\n",
    "    Increase the number of estimators (e.g. 1024) and visualize the impact on performance. You might have to adapt the learning rate.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features hashing and random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We restart with raw features before dummy encoding: Xtrain, Xtest.\n",
    "<font color=\"red\">**Question 43**:\n",
    "    Display again the number of modalities per feature in Xtrain.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to define a transformation which regroups the least frequent modalities into a label 'isRare'. In order to do so, we decide to define our own Transformer.\n",
    "<font color=\"red\">**Question 44**:\n",
    "    Understand the different steps of 'fit' and 'transform'.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MergeRareTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col_names, threshold):\n",
    "        self.col_names = col_names\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        X = pd.DataFrame(X)\n",
    "        counts_dict_list = []\n",
    "        ################## READ THIS #########################\n",
    "        for i in range(len(self.col_names)):\n",
    "            \n",
    "            serie = X[self.col_names[i]].value_counts()  # Série des counts de chaque modalité\n",
    "            rare_indexes = serie[serie<self.threshold[i]].index  # A quoi correspondent ces indices ?\n",
    "            frequent_indexes = serie[serie>=self.threshold[i]].index  # A quoi correspondent ces indices ?\n",
    "            dico = {x:'isRare' for x in rare_indexes}\n",
    "            dico.update({x: str(x) for x in frequent_indexes})\n",
    "            counts_dict_list.append(dico)   # Quel est le dictionnaire obtenu ?\n",
    "            \n",
    "        ######################################################\n",
    "            \n",
    "        self.counts_dict_list_ = counts_dict_list\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        Xt = pd.DataFrame()\n",
    "        ################## READ THIS #########################\n",
    "        for col, count_dict in zip(self.col_names, self.counts_dict_list_):\n",
    "            Xt[col] = X[col].apply(lambda x:count_dict[x] if x in count_dict else 'isRare')\n",
    "            # A quoi sert le \"else 'isRare'\" dans la transformation de la colonne ?\n",
    "        ######################################################\n",
    "\n",
    "        return Xt\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 45:**\n",
    "    <br>\n",
    "    - Fit and transform the training set. To do so, merge all mmodalities occuring at least 20 times in each column.\n",
    "    <br>\n",
    "    - Transform the test set.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = MergeRareTransformer(col_names=Xtrain.columns, threshold=[20]*len(Xtrain.columns))\n",
    "Xtrain_mg = ... # Fill here with fit_transform or fit then transform.\n",
    "Xtest_mg = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 46:**\n",
    "   How many elements of the column Xtrain_mg['app_domain'] are now labeled as 'rare'?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 47:**\n",
    "   In the new train set, display the number of modalities for each feature.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modalities are arbitrary object, such as '234', 'isRare', etc. We will now transorm them into integers with the hashing trick.\n",
    "<font color=\"red\">**Question 48:**\n",
    "   To better understand how the 'hash' function is working, apply it to a string of your choice.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "hash( ... ) # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 49:**\n",
    "   Create two new datasets 'Xtrain_ha' and 'Xtest_ha' containing the output of the hashing process. Use the '.apply' method to transform iteratively the columns by mapping to each value its remainder in the euclidean division of the hash by 1000000. \n",
    "   Example:\n",
    "</font>\n",
    "</font>\n",
    "<p>\n",
    "<center>\n",
    "2060777048690<font color=\"red\">918393</font>  -->  918393\n",
    "</center>\n",
    "Remark: do not forget that the function 'hash' has to take a string as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_ha = pd.DataFrame()\n",
    "Xtest_ha = pd.DataFrame()\n",
    "for col in Xtrain_mg.columns:\n",
    "    Xtrain_ha[col] = Xtrain_mg[col].apply( ... ) # Fill here defining a lambda function\n",
    "    Xtest_ha[col] = Xtest_mg[col].apply( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 50:**\n",
    "   Visualize the content of the DataFrames you have obtained.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 51:**\n",
    "    <br>\n",
    "    - Train a RandomForestClassifier on Xtrain_ha and evaluate its performance on Xtest_ha. One can chose 1024 estimators, min_samples_leaf=20 and verbose=1 in order to monitor the fitting step.\n",
    "    <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ... # Fill here\n",
    "rf = RandomForestClassifier( ... )\n",
    "rf.fit( ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = ...\n",
    "log_loss(...), roc_auc_score(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 52:**\n",
    "   Compare with xgboost performance on the same hashed dataset.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here\n",
    "%time xgb.fit( ..., ... ) # the '%time' command will return the execution time of the fitting step\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 53:**\n",
    "    Plot the ROC and the lift curves for the obtained classifier (xgboost on hashed data).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the lift curve here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashing produces columns of integers arbitrarily ordered. One can wonder if adding more columns hashed in a different fashion would lead to better performance. \n",
    "<font color=\"red\">**Question 54:**\n",
    "    Add hashed columns by recursively hashing the previous ones: complete the following code. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_haha = pd.DataFrame(Xtrain_ha).copy()\n",
    "Xtest_haha = pd.DataFrame(Xtest_ha).copy()\n",
    "\n",
    "n_hash = 3\n",
    "cols = Xtrain_ha.columns\n",
    "for l in range(n_hash):\n",
    "    for col in cols:\n",
    "        Xtrain_haha[col + '-hash'] = Xtrain_haha[col].apply( ... )\n",
    "        Xtest_haha[col + '-hash'] = Xtest_haha[col].apply( ... )\n",
    "    cols = [col + '-hash' for col in cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 55:**\n",
    "    Evaluate the performance of a random forest and/or an xgboost clasifier on these enlarged dataset.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # Fill here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 55:**\n",
    "    Compare the different models used in the TP.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... Enter your comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! :-) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
