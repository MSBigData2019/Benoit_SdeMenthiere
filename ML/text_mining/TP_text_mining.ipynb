{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T15:53:21.579139Z",
     "start_time": "2018-11-29T15:53:20.697281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "run sentimentanalysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:51:01.429083Z",
     "start_time": "2018-11-29T11:51:01.425536Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T15:53:38.277863Z",
     "start_time": "2018-11-29T15:53:38.270451Z"
    }
   },
   "outputs": [],
   "source": [
    "texts[0].split();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T15:53:48.965461Z",
     "start_time": "2018-11-29T15:53:48.958968Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_word(text):\n",
    "    words_text = text.split()\n",
    "    unique, count = np.unique(words_text, return_counts=True)\n",
    "    return pd.Series(dict(zip(unique, count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T15:56:57.432834Z",
     "start_time": "2018-11-29T15:56:57.418725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "!            3\n",
       "\"           10\n",
       "&            1\n",
       "(            9\n",
       ")            9\n",
       ",           44\n",
       "-            7\n",
       ".           34\n",
       "10/10        2\n",
       "2            1\n",
       "20           1\n",
       "3            1\n",
       "4/10         1\n",
       "7/10         2\n",
       "8/10         1\n",
       "9/10         2\n",
       ":            3\n",
       "?            6\n",
       "a           14\n",
       "about        2\n",
       "accident     1\n",
       "actors       1\n",
       "actually     2\n",
       "after        2\n",
       "again        2\n",
       "ago          1\n",
       "all          6\n",
       "also         1\n",
       "although     1\n",
       "always       1\n",
       "            ..\n",
       "up           2\n",
       "us           1\n",
       "very         2\n",
       "video        1\n",
       "visions      1\n",
       "want         1\n",
       "watch        1\n",
       "way          2\n",
       "ways         1\n",
       "we           4\n",
       "weird        1\n",
       "well         1\n",
       "wes          1\n",
       "what         2\n",
       "what's       2\n",
       "whatever     1\n",
       "when         1\n",
       "where's      1\n",
       "which        4\n",
       "while        1\n",
       "who          3\n",
       "witch        1\n",
       "with         5\n",
       "world        2\n",
       "would        1\n",
       "wrapped      1\n",
       "write        1\n",
       "years        1\n",
       "you          3\n",
       "your         2\n",
       "Length: 353, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_word(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T15:53:49.955507Z",
     "start_time": "2018-11-29T15:53:49.947861Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_words(texts, count_word=count_word):\n",
    "    data = map(count_word, texts)\n",
    "    concat = pd.concat(data, axis = 1, ignore_index=True, sort=False)\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T15:54:12.532989Z",
     "start_time": "2018-11-29T15:53:52.528784Z"
    }
   },
   "outputs": [],
   "source": [
    "count_words(texts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:45:42.710113Z",
     "start_time": "2018-11-29T11:45:42.678249Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class NB(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, count_words=count_words):\n",
    "        self._count_words = count_words\n",
    "\n",
    "    def fit(self, texts, y):\n",
    "        concat = self._count_words(texts)\n",
    "        self.vocab = {k:v for v, k in enumerate(list(concat.index))}\n",
    "        V = set(concat.index)\n",
    "        N = len(texts)\n",
    "        self.C, counts = np.unique(y, return_counts=True)\n",
    "        self.prior = {}\n",
    "        self.condprob = {}\n",
    "        for classe in self.C:\n",
    "            Nc = counts[classe]\n",
    "            self.prior[classe] = Nc / N\n",
    "            text_c = concat.iloc[:,y==classe]\n",
    "            count = text_c.sum(axis=1)\n",
    "            self.condprob[classe] = (count+1)/sum(count+1)\n",
    "        return V, self.prior, self.condprob\n",
    "\n",
    "    def _predict_(self, text):\n",
    "        W = text.split()\n",
    "        score = {}\n",
    "        for classe in self.C:\n",
    "            score[classe]= math.log(self.prior[classe])\n",
    "            for t in W:\n",
    "                try:\n",
    "                    score[classe]+= math.log(self.condprob[classe][self.vocab[t]])\n",
    "                except:\n",
    "                    pass\n",
    "        return max(score, key=score.get)\n",
    "    \n",
    "    def predict(self, texts):\n",
    "        return list(map(self._predict_, texts))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        return np.mean( np.array(pred) == np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:46:35.297454Z",
     "start_time": "2018-11-29T11:46:14.001123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'potty',\n",
       "  'him/herself',\n",
       "  'half-stated',\n",
       "  'vaporize',\n",
       "  'terse',\n",
       "  'whos',\n",
       "  'brash',\n",
       "  'chelcie',\n",
       "  'debris',\n",
       "  'aa',\n",
       "  'shoot-ups',\n",
       "  \"gosse's\",\n",
       "  'yulin',\n",
       "  'seing',\n",
       "  'shread',\n",
       "  'spoofy',\n",
       "  'carolco',\n",
       "  'graveyards',\n",
       "  'danced',\n",
       "  'sikh',\n",
       "  'paraplegic',\n",
       "  'lan',\n",
       "  'bull-crap',\n",
       "  'spielberg-inspired',\n",
       "  'suitably',\n",
       "  'trenchcoat',\n",
       "  \"tulips'\",\n",
       "  \"material's\",\n",
       "  'captor',\n",
       "  'capably',\n",
       "  \"hogarth's\",\n",
       "  'muslim',\n",
       "  '`bring',\n",
       "  'egos',\n",
       "  'viruses',\n",
       "  \"garicia's\",\n",
       "  'slake',\n",
       "  'mistrustful',\n",
       "  'bubble',\n",
       "  'pseudo-epic',\n",
       "  'reville',\n",
       "  'toast',\n",
       "  'chunnel',\n",
       "  'liner',\n",
       "  'wallet',\n",
       "  'percussive',\n",
       "  'chauffeur-driven',\n",
       "  'hardly',\n",
       "  'headliner',\n",
       "  'yielded',\n",
       "  'before---and',\n",
       "  'hopping',\n",
       "  \"what're\",\n",
       "  '29-year-old',\n",
       "  \"'amateur'\",\n",
       "  'afterthought',\n",
       "  'tale',\n",
       "  'gray',\n",
       "  'critic',\n",
       "  'imbecilic',\n",
       "  'amassed',\n",
       "  'awkward',\n",
       "  'anakin',\n",
       "  'squeaky',\n",
       "  'crotchety',\n",
       "  'tracer',\n",
       "  'non-fiction',\n",
       "  'impart',\n",
       "  'familiar',\n",
       "  'already-chaotic',\n",
       "  'freakish',\n",
       "  \"gadget's\",\n",
       "  'katy',\n",
       "  'droopy-eyed',\n",
       "  \"vianne's\",\n",
       "  'banners',\n",
       "  'hors',\n",
       "  'branching',\n",
       "  'would-be',\n",
       "  'negotiate',\n",
       "  'vegans',\n",
       "  'splish',\n",
       "  'beginning--while',\n",
       "  'larceny',\n",
       "  'asexually',\n",
       "  \"taxpayer's\",\n",
       "  'stretched',\n",
       "  'prolong',\n",
       "  'processions',\n",
       "  'presence',\n",
       "  'absurdity',\n",
       "  'perched',\n",
       "  'infra-red',\n",
       "  'teams',\n",
       "  'securing',\n",
       "  'then-unknown',\n",
       "  'handguns',\n",
       "  'subterfuge',\n",
       "  'craftsmen',\n",
       "  'hebrew',\n",
       "  'reagan',\n",
       "  'heimlich',\n",
       "  'twelve-year-old',\n",
       "  'dulled',\n",
       "  'neri',\n",
       "  \"jeunet's\",\n",
       "  'thorne',\n",
       "  'delpy',\n",
       "  'pre-1960s',\n",
       "  'instructions',\n",
       "  'lip-synch',\n",
       "  'rza',\n",
       "  'weakness',\n",
       "  'whitlow',\n",
       "  'hers',\n",
       "  'climate-controlling',\n",
       "  'sleepy',\n",
       "  'sing-song',\n",
       "  'stopover',\n",
       "  'crackers',\n",
       "  \"lord's\",\n",
       "  'essays',\n",
       "  'boyhood--and',\n",
       "  'underdevelopment',\n",
       "  'playfully',\n",
       "  'take-no-prisoners',\n",
       "  'slum',\n",
       "  'collage',\n",
       "  'benj',\n",
       "  'put',\n",
       "  'facade',\n",
       "  'bikini',\n",
       "  'eccentric',\n",
       "  'recitals',\n",
       "  'stoppard',\n",
       "  'slushee',\n",
       "  'shortened',\n",
       "  \"berkley's\",\n",
       "  'hospital',\n",
       "  'inxs',\n",
       "  \"feel'\",\n",
       "  'lestat',\n",
       "  'not-so-glorious',\n",
       "  'unconsummated',\n",
       "  'rituals',\n",
       "  'macnamara',\n",
       "  \"magoo's\",\n",
       "  'mailheart',\n",
       "  'cradles',\n",
       "  'horrors--bad',\n",
       "  'americana',\n",
       "  'roshomon-like',\n",
       "  'overlaid',\n",
       "  'identification',\n",
       "  'rubens',\n",
       "  'honor',\n",
       "  'packers',\n",
       "  'feeble-minded',\n",
       "  'payback',\n",
       "  'singer/alcoholic',\n",
       "  'chappy',\n",
       "  'ghandi',\n",
       "  'demonstrations',\n",
       "  \"dorian's\",\n",
       "  'ego',\n",
       "  'bobbitt',\n",
       "  'beans',\n",
       "  'bronson',\n",
       "  'brainy',\n",
       "  'russel',\n",
       "  'classmate',\n",
       "  'near-riot',\n",
       "  'rubbery',\n",
       "  'contributors',\n",
       "  \"diner'\",\n",
       "  'froehlich',\n",
       "  'harvard',\n",
       "  'undone',\n",
       "  'drug-addiction',\n",
       "  'talkshow',\n",
       "  'praises',\n",
       "  'thisclosefromdeath',\n",
       "  'none',\n",
       "  'laserdiscs',\n",
       "  'uploading',\n",
       "  '112',\n",
       "  'inventively',\n",
       "  'mabe',\n",
       "  'hijinks-addled',\n",
       "  'muddling',\n",
       "  'outsiders',\n",
       "  'constitution',\n",
       "  'variable',\n",
       "  \"butcher's\",\n",
       "  'three-year-olds',\n",
       "  'autobiography',\n",
       "  'melodramatic',\n",
       "  'sidebars',\n",
       "  'fastfood',\n",
       "  'busting',\n",
       "  'stalkings',\n",
       "  'neptune',\n",
       "  'speilberg',\n",
       "  'missteps',\n",
       "  'anti-semitic',\n",
       "  'all-encompassing',\n",
       "  \"acres'\",\n",
       "  'detracts',\n",
       "  'tapped',\n",
       "  \"'moving'\",\n",
       "  'thing__about',\n",
       "  'smart-assed',\n",
       "  'multi-tiered',\n",
       "  '_death',\n",
       "  'coca-cola',\n",
       "  'anticlimax',\n",
       "  'saturday-night-friendly',\n",
       "  'oldish',\n",
       "  'mitch',\n",
       "  \"spall's\",\n",
       "  'stabbed',\n",
       "  \"pbs'\",\n",
       "  'father-daughter',\n",
       "  'has-been',\n",
       "  'over-thought',\n",
       "  'prepared',\n",
       "  'beaudene',\n",
       "  'petey',\n",
       "  'geographic',\n",
       "  'ramius',\n",
       "  'dreams/fantasies',\n",
       "  'behemoth',\n",
       "  '24',\n",
       "  \"ricci's\",\n",
       "  \"impossible'\",\n",
       "  'contractually-obligated',\n",
       "  'knish',\n",
       "  'macy',\n",
       "  'broderick',\n",
       "  'coup',\n",
       "  'anya',\n",
       "  'waikiki',\n",
       "  'previous',\n",
       "  'letting',\n",
       "  \"hawks'\",\n",
       "  'infamous',\n",
       "  'perpetuate',\n",
       "  'condition--non-studio',\n",
       "  \"hollow'\",\n",
       "  'vanity',\n",
       "  'bullworths',\n",
       "  'arranges',\n",
       "  'cures',\n",
       "  'menges',\n",
       "  'beautician',\n",
       "  \"catch's\",\n",
       "  'un-flashy',\n",
       "  'mgm',\n",
       "  \"valek's\",\n",
       "  'tch',\n",
       "  'vomity',\n",
       "  'defendant',\n",
       "  'approached',\n",
       "  'stowaway',\n",
       "  'hanger',\n",
       "  'florida-set',\n",
       "  'father-and-son',\n",
       "  'phallus',\n",
       "  'miscegenation',\n",
       "  'dionna',\n",
       "  'bears_',\n",
       "  'holds-barred',\n",
       "  'reads',\n",
       "  'ailment',\n",
       "  'sickeningly',\n",
       "  'basking',\n",
       "  'derailing',\n",
       "  'enjoying',\n",
       "  'heroin-chic',\n",
       "  'timm',\n",
       "  'oozed',\n",
       "  'pine',\n",
       "  'shopper',\n",
       "  'cell',\n",
       "  'submarine',\n",
       "  \"wittliff's\",\n",
       "  'imperious',\n",
       "  'collapse',\n",
       "  'goofy-looking',\n",
       "  'sidewalk',\n",
       "  'dreadfully',\n",
       "  'bootlegging',\n",
       "  'thomson',\n",
       "  'late-entry',\n",
       "  'phasers',\n",
       "  'story_',\n",
       "  'socks',\n",
       "  'local',\n",
       "  'mustache-see',\n",
       "  'ia',\n",
       "  'flawed',\n",
       "  'cowards',\n",
       "  'buffalo-hunting',\n",
       "  'shit-terpiece',\n",
       "  \"america'\",\n",
       "  'drowned',\n",
       "  'bluesman',\n",
       "  'crumble',\n",
       "  'super-agent',\n",
       "  'sell-out',\n",
       "  'sats',\n",
       "  'participates',\n",
       "  'hynes',\n",
       "  'morricone',\n",
       "  \"measurement's\",\n",
       "  'reanimator',\n",
       "  'memphis',\n",
       "  'unmitigated',\n",
       "  'isn+t',\n",
       "  'goofily',\n",
       "  'impersonation',\n",
       "  'ketchup',\n",
       "  'audiotape',\n",
       "  'qe2',\n",
       "  'writer/director/comedian',\n",
       "  'epigraph',\n",
       "  'arab-speaking',\n",
       "  'running-like-the-wind-prey',\n",
       "  'sneeze',\n",
       "  'donager',\n",
       "  \"walker's\",\n",
       "  'funner',\n",
       "  'false',\n",
       "  'demonstrable',\n",
       "  'signaling',\n",
       "  'henstridge',\n",
       "  \"tomorrow'\",\n",
       "  \"doogie's\",\n",
       "  'anatomical',\n",
       "  'arch-enemy',\n",
       "  \"stayin'\",\n",
       "  'queen',\n",
       "  \"spears'\",\n",
       "  'henslowe',\n",
       "  'teen-accessible',\n",
       "  'multiracial',\n",
       "  'selleck',\n",
       "  'under-developed',\n",
       "  'imply',\n",
       "  'fried',\n",
       "  'sprawling',\n",
       "  'tenant',\n",
       "  'disgruntled',\n",
       "  '18+',\n",
       "  'rectitude',\n",
       "  'slutty',\n",
       "  'shed',\n",
       "  'converts',\n",
       "  'realizations',\n",
       "  'regains',\n",
       "  'collette',\n",
       "  'punctuated',\n",
       "  'pfarrer',\n",
       "  'tatopolous',\n",
       "  '2024',\n",
       "  'dougherty',\n",
       "  'better-known',\n",
       "  'downshifts',\n",
       "  'doreen',\n",
       "  '>honk',\n",
       "  'backpacks',\n",
       "  'flexes',\n",
       "  'bijou',\n",
       "  'erasing',\n",
       "  'compensation',\n",
       "  'fatally',\n",
       "  'analysis',\n",
       "  'climbs',\n",
       "  'lover/prot',\n",
       "  'sucking-out',\n",
       "  'charmingly',\n",
       "  'remade',\n",
       "  'britton',\n",
       "  'oneders',\n",
       "  'digits',\n",
       "  'madeliene',\n",
       "  'objectionable',\n",
       "  'remastered',\n",
       "  'futility',\n",
       "  'common',\n",
       "  'pejorative',\n",
       "  'velociraptor',\n",
       "  'painting',\n",
       "  'age-old',\n",
       "  \"saddam's\",\n",
       "  'entertaining',\n",
       "  'jasper',\n",
       "  'noraruth@aol',\n",
       "  'manipulation',\n",
       "  'sian',\n",
       "  'howdy',\n",
       "  'time-lapse',\n",
       "  'thrill',\n",
       "  'bandaras',\n",
       "  '42',\n",
       "  'recreations',\n",
       "  'testing',\n",
       "  'competed',\n",
       "  'vietnam',\n",
       "  'antagonist--unstoppable',\n",
       "  'installed',\n",
       "  'discovered',\n",
       "  'sugiyama',\n",
       "  \"cassandra's\",\n",
       "  'rousingly',\n",
       "  'fact--that',\n",
       "  'best-supporting',\n",
       "  \"montague's\",\n",
       "  'perceptively',\n",
       "  'cosmopolitan',\n",
       "  'measures',\n",
       "  '16-year-old',\n",
       "  'coordinates',\n",
       "  'crewmate',\n",
       "  'backstage',\n",
       "  'jarvis',\n",
       "  'bison',\n",
       "  'stomping',\n",
       "  'erm',\n",
       "  'foray',\n",
       "  \"aaliyah's\",\n",
       "  \"gyllenhall's\",\n",
       "  'marvel',\n",
       "  'scenic',\n",
       "  'oversight',\n",
       "  'monstrosity',\n",
       "  'victor',\n",
       "  'noteriaty',\n",
       "  'first-produced',\n",
       "  'we',\n",
       "  'gooey',\n",
       "  'taran',\n",
       "  'lindberg',\n",
       "  'well-suited',\n",
       "  'siskel',\n",
       "  'crosses',\n",
       "  'warlock',\n",
       "  'convalescence',\n",
       "  'motherly',\n",
       "  'catholic',\n",
       "  'heroines',\n",
       "  'nine',\n",
       "  'pfeiffer',\n",
       "  'scatalogical',\n",
       "  'feints',\n",
       "  'so-bright',\n",
       "  'tusken',\n",
       "  \"swinton's\",\n",
       "  \"oteri's\",\n",
       "  'gotham',\n",
       "  'door',\n",
       "  'preservation--',\n",
       "  \"childhood's\",\n",
       "  'evidencing',\n",
       "  'taglines',\n",
       "  'screen-viewer',\n",
       "  'headphones',\n",
       "  'syncing',\n",
       "  \"d'aragon\",\n",
       "  \"fallen's\",\n",
       "  'must-be-improvised',\n",
       "  'swansong',\n",
       "  '`real',\n",
       "  'aggrieved',\n",
       "  'audience',\n",
       "  'exteriors',\n",
       "  'substitution',\n",
       "  'amoral',\n",
       "  'earth',\n",
       "  'buton',\n",
       "  'remembered',\n",
       "  \"hot-fudge-rockin'\",\n",
       "  'tangle',\n",
       "  'paragraph',\n",
       "  'compared',\n",
       "  'pritchett',\n",
       "  'slates',\n",
       "  'poolboy',\n",
       "  'schoolteacher',\n",
       "  'dragging/salting',\n",
       "  \"maurice's\",\n",
       "  're-powering',\n",
       "  'juan',\n",
       "  'oriented',\n",
       "  'parading',\n",
       "  'disgust',\n",
       "  'shrugged',\n",
       "  'cross-dressing',\n",
       "  'avoidance',\n",
       "  'ugly',\n",
       "  'doubted',\n",
       "  'redeemed',\n",
       "  'journalists',\n",
       "  'psychology',\n",
       "  'ditch',\n",
       "  'staking',\n",
       "  'forrest',\n",
       "  'infiltrating',\n",
       "  \"liotta's\",\n",
       "  'miner',\n",
       "  'ever-attentive',\n",
       "  'bickers',\n",
       "  'teammates',\n",
       "  'ferret',\n",
       "  'resuscitated',\n",
       "  'gaghan',\n",
       "  'duffel',\n",
       "  'stares',\n",
       "  'scream-mask',\n",
       "  'heterosexual',\n",
       "  'blackman',\n",
       "  'nan',\n",
       "  'buzzwords',\n",
       "  'mcemployees',\n",
       "  'rundown',\n",
       "  'bleeding',\n",
       "  'clashed',\n",
       "  'construct',\n",
       "  \"'threatening\",\n",
       "  'jingoistic',\n",
       "  'ernie',\n",
       "  'slowest',\n",
       "  'yipes',\n",
       "  'voices/accents',\n",
       "  \"odin's\",\n",
       "  'petitions',\n",
       "  'pasts',\n",
       "  'enriched',\n",
       "  'one-word',\n",
       "  'financially',\n",
       "  'graves',\n",
       "  'overflowing',\n",
       "  'flyboys',\n",
       "  'roommates',\n",
       "  'elie',\n",
       "  'maureen',\n",
       "  'ideology',\n",
       "  'pairing',\n",
       "  'sawalha',\n",
       "  'hurlyburly',\n",
       "  'gauge',\n",
       "  'quirky-but-realistic',\n",
       "  'pastel',\n",
       "  'handled',\n",
       "  'macks',\n",
       "  'wags',\n",
       "  \"mcpherson's\",\n",
       "  'intertwines',\n",
       "  'breach',\n",
       "  'def',\n",
       "  'sugarry',\n",
       "  'martindale',\n",
       "  'abberline',\n",
       "  'cannery',\n",
       "  'occupying',\n",
       "  'online',\n",
       "  'striptease',\n",
       "  'yearnings',\n",
       "  'lessons',\n",
       "  'struggling',\n",
       "  'attended',\n",
       "  \"denny's\",\n",
       "  'serving',\n",
       "  'tv2',\n",
       "  'encouraging',\n",
       "  'chunky',\n",
       "  'michelangelo',\n",
       "  'e-dreams',\n",
       "  'sunlit',\n",
       "  '`one',\n",
       "  'join',\n",
       "  'omegahedron',\n",
       "  'punishable',\n",
       "  'miep',\n",
       "  'torro',\n",
       "  'much--and',\n",
       "  'upholstered',\n",
       "  \"`ultra-stylish'\",\n",
       "  'feign',\n",
       "  'resurfaces',\n",
       "  'bravo',\n",
       "  \"killer's\",\n",
       "  'woodenly',\n",
       "  'tagging',\n",
       "  'davidson',\n",
       "  'marsha',\n",
       "  'two-day',\n",
       "  'jams',\n",
       "  'dank',\n",
       "  'boobs',\n",
       "  'sticker',\n",
       "  '_fifty_',\n",
       "  'potatohead',\n",
       "  'third-class-party',\n",
       "  'homogenize',\n",
       "  'ultra-secret',\n",
       "  'beasts',\n",
       "  'condense',\n",
       "  'yorick',\n",
       "  'glorify',\n",
       "  'has-beens',\n",
       "  'apprehensions',\n",
       "  'cohesiveness',\n",
       "  'giggly',\n",
       "  'near-greatness',\n",
       "  'mousetrap',\n",
       "  \"homage'\",\n",
       "  'eligibility',\n",
       "  'blot',\n",
       "  'wanker',\n",
       "  'krueger',\n",
       "  'cobblers',\n",
       "  'ali',\n",
       "  'f--k',\n",
       "  \"juliet's\",\n",
       "  're-introduced',\n",
       "  'strikeout',\n",
       "  'blockubuster',\n",
       "  'forms',\n",
       "  \"'69\",\n",
       "  'grudging',\n",
       "  'well-plotted',\n",
       "  'bundles',\n",
       "  'ditz',\n",
       "  'dustin',\n",
       "  'decapitate',\n",
       "  'legible',\n",
       "  'obesity',\n",
       "  'marksman',\n",
       "  'brown-it',\n",
       "  'decades-spanning',\n",
       "  \"cabot's\",\n",
       "  'explosiveness',\n",
       "  'paid',\n",
       "  'introductory',\n",
       "  'snap',\n",
       "  'granite',\n",
       "  'cross-cutting',\n",
       "  'one-hour',\n",
       "  'wowed',\n",
       "  'thrugh',\n",
       "  'permanently',\n",
       "  'sitcom-bred',\n",
       "  'avaricious',\n",
       "  'rolling',\n",
       "  'casualness',\n",
       "  '8-minute',\n",
       "  'climb',\n",
       "  'bald',\n",
       "  \"hall's\",\n",
       "  'warhol',\n",
       "  'berry',\n",
       "  'omniscient',\n",
       "  'moi',\n",
       "  'porthos',\n",
       "  'multi-picture',\n",
       "  'psychos',\n",
       "  'ballad',\n",
       "  'topol',\n",
       "  'valencia',\n",
       "  'labels',\n",
       "  'coke-head',\n",
       "  'threaten',\n",
       "  'immersed',\n",
       "  'narcotics',\n",
       "  'impersonates',\n",
       "  'koslova',\n",
       "  'x-philes',\n",
       "  'aurally',\n",
       "  'regenerated',\n",
       "  'pro-porn',\n",
       "  'gluttony',\n",
       "  'commercial-like',\n",
       "  'cavity',\n",
       "  'nicely-understated',\n",
       "  '10-year',\n",
       "  'side-effects',\n",
       "  'annette',\n",
       "  'near-flawless',\n",
       "  'direcing',\n",
       "  'darts',\n",
       "  'sings--and',\n",
       "  'otter',\n",
       "  'guesswork',\n",
       "  'headhunter',\n",
       "  'lockup',\n",
       "  'azure',\n",
       "  \"losers'\",\n",
       "  'denizens',\n",
       "  'sixteen',\n",
       "  'television-addicted',\n",
       "  'retrieves',\n",
       "  'fruit',\n",
       "  'underneath-',\n",
       "  \"wells'\",\n",
       "  'reinserted',\n",
       "  'vassili',\n",
       "  'costners',\n",
       "  'designer',\n",
       "  'whirlwinds',\n",
       "  'vests',\n",
       "  'isaach',\n",
       "  'repay',\n",
       "  'cartoonish',\n",
       "  'mid-1500s',\n",
       "  'primed',\n",
       "  'downloaded',\n",
       "  'hazzard',\n",
       "  'cheesiness',\n",
       "  'jetsons-like',\n",
       "  'ballard',\n",
       "  'trickle',\n",
       "  'einstein-level',\n",
       "  '19th',\n",
       "  'schlondorff',\n",
       "  'himself',\n",
       "  'miracle',\n",
       "  'nowak',\n",
       "  'squeeze',\n",
       "  'interracial',\n",
       "  'timecop',\n",
       "  'snyder',\n",
       "  'bancroft',\n",
       "  'colada',\n",
       "  'scope',\n",
       "  \"lambeau's\",\n",
       "  'unions',\n",
       "  'meals',\n",
       "  'doug',\n",
       "  'conglomerates--have',\n",
       "  'cultured',\n",
       "  'off-screen',\n",
       "  'boasting',\n",
       "  'baird',\n",
       "  'preference',\n",
       "  'fascism',\n",
       "  'doohan',\n",
       "  'prohibits',\n",
       "  'cesar',\n",
       "  'sockets',\n",
       "  \"`candyman'\",\n",
       "  'has',\n",
       "  'money-making',\n",
       "  'jump-roping',\n",
       "  '92-minute',\n",
       "  'not-so-obvious',\n",
       "  '`',\n",
       "  'keyhole',\n",
       "  'leggings',\n",
       "  'homies',\n",
       "  'contrivance',\n",
       "  'persson',\n",
       "  'bellowing',\n",
       "  'man-meets-alien',\n",
       "  \"michell's\",\n",
       "  'nanni',\n",
       "  'trotted',\n",
       "  '_basquiat_',\n",
       "  \"o'barr\",\n",
       "  \"monster's\",\n",
       "  'suspect',\n",
       "  'retriever',\n",
       "  'racing',\n",
       "  'joins',\n",
       "  'sexualized',\n",
       "  \"villains'\",\n",
       "  'fatigues',\n",
       "  'midler',\n",
       "  'superhero/action',\n",
       "  'cult',\n",
       "  'confidentiality',\n",
       "  'pre-conceptions',\n",
       "  'confessions',\n",
       "  'cattrall',\n",
       "  'grinder',\n",
       "  'earn',\n",
       "  '1865',\n",
       "  'premieres',\n",
       "  'breakdown',\n",
       "  'case',\n",
       "  'captions',\n",
       "  'volcanoes',\n",
       "  'games',\n",
       "  'broadcast',\n",
       "  'variant',\n",
       "  'proclivity',\n",
       "  'cliched',\n",
       "  'clocktower',\n",
       "  'nicest',\n",
       "  'skeeter',\n",
       "  'kieslowski',\n",
       "  \"ribisi's\",\n",
       "  '21-year-old',\n",
       "  'vent',\n",
       "  \"mob's\",\n",
       "  'devito',\n",
       "  'carved',\n",
       "  'arises',\n",
       "  'willard',\n",
       "  'arangements',\n",
       "  'anthropologist',\n",
       "  'rewarded',\n",
       "  'shifts',\n",
       "  'absorbed',\n",
       "  'lowest-common-denominator',\n",
       "  \"diedre's\",\n",
       "  'francis',\n",
       "  '_life',\n",
       "  'asking',\n",
       "  'langton',\n",
       "  'unimpressive',\n",
       "  'spinella',\n",
       "  'pay-per-view',\n",
       "  'sayings',\n",
       "  'non-offensive',\n",
       "  'berenger',\n",
       "  'actor/waiter',\n",
       "  'hope/crosby',\n",
       "  'toucha',\n",
       "  'smurfs',\n",
       "  'instill',\n",
       "  'quart',\n",
       "  'rip-roaring',\n",
       "  '34-degree',\n",
       "  'talks',\n",
       "  'smoke',\n",
       "  'floating',\n",
       "  'gamut',\n",
       "  'aaaahhhs',\n",
       "  'equipment',\n",
       "  'holt',\n",
       "  'ogled',\n",
       "  'you=92ll',\n",
       "  'lynched',\n",
       "  'languishing',\n",
       "  'chuckles',\n",
       "  'bava',\n",
       "  'dooming',\n",
       "  'melodramatic--but',\n",
       "  'gangland',\n",
       "  'much-ballyhooed',\n",
       "  'prophesized',\n",
       "  'strasser',\n",
       "  'opportunities',\n",
       "  'response',\n",
       "  'conspiracies',\n",
       "  'boat',\n",
       "  'injections',\n",
       "  '132',\n",
       "  'gallo',\n",
       "  'clubs',\n",
       "  \"partygoers'\",\n",
       "  'bundled',\n",
       "  'ether',\n",
       "  'wowing',\n",
       "  'streamline',\n",
       "  'drafted',\n",
       "  \"batter's\",\n",
       "  'moonraker',\n",
       "  'tilly',\n",
       "  'bubbles',\n",
       "  'dunno',\n",
       "  'occupied',\n",
       "  'homeless',\n",
       "  'bra',\n",
       "  'tibetans',\n",
       "  '1948',\n",
       "  'brinks',\n",
       "  'cagney',\n",
       "  'caldwell',\n",
       "  'nch',\n",
       "  'monument',\n",
       "  'tenley',\n",
       "  'duvall',\n",
       "  'sadsacks',\n",
       "  'monet',\n",
       "  'obviously-inserted',\n",
       "  'breathers',\n",
       "  'tati',\n",
       "  'prompting',\n",
       "  'meteorite',\n",
       "  'self-control',\n",
       "  'abrasive',\n",
       "  'jumpy',\n",
       "  'mulroney',\n",
       "  '-based',\n",
       "  'refunds',\n",
       "  'game-plan',\n",
       "  'towel',\n",
       "  'handyman',\n",
       "  'one-and-a-half',\n",
       "  'peek-a-boo',\n",
       "  'coiffed',\n",
       "  \"tunney's\",\n",
       "  'uber-rich',\n",
       "  'straps',\n",
       "  'jeffrey',\n",
       "  'sciorra',\n",
       "  'not-very-good',\n",
       "  'travels',\n",
       "  \"hadden's\",\n",
       "  'sexiest',\n",
       "  'cherry-colored',\n",
       "  'chainsmokes',\n",
       "  'is--gasp',\n",
       "  'blandly',\n",
       "  'dussander',\n",
       "  'neutrality',\n",
       "  'sideshow',\n",
       "  \"quentin's\",\n",
       "  'rootless',\n",
       "  'cut',\n",
       "  'flakes',\n",
       "  'ut',\n",
       "  'barks',\n",
       "  'lightest',\n",
       "  'hammerbottom',\n",
       "  'quo',\n",
       "  'sobriety',\n",
       "  'dostoevski',\n",
       "  \"`batman'\",\n",
       "  'insecurity',\n",
       "  'indomitable',\n",
       "  'ticking',\n",
       "  'fights--especially',\n",
       "  'awesomeness',\n",
       "  'united',\n",
       "  'pilson',\n",
       "  'region',\n",
       "  'lewinsky',\n",
       "  'largest',\n",
       "  \"kickin'\",\n",
       "  \"indie-films'\",\n",
       "  \"amblyn's\",\n",
       "  'hut',\n",
       "  'roof',\n",
       "  'jacket',\n",
       "  'riffs',\n",
       "  'recommened',\n",
       "  'buckles',\n",
       "  'whitfield',\n",
       "  'flapping',\n",
       "  \"nature's\",\n",
       "  'twins',\n",
       "  'overview',\n",
       "  'devastated',\n",
       "  'derived',\n",
       "  'modest',\n",
       "  \"duke's\",\n",
       "  'disturb',\n",
       "  \"shirase's\",\n",
       "  'hohh',\n",
       "  'starships',\n",
       "  'souza',\n",
       "  'separations',\n",
       "  'ocean-going',\n",
       "  'exemplify',\n",
       "  'castrate',\n",
       "  'survival',\n",
       "  '$35',\n",
       "  'amalgamation',\n",
       "  'varela',\n",
       "  \"o'brady\",\n",
       "  'operating',\n",
       "  'telescopes',\n",
       "  'dumbo',\n",
       "  \"labyrinth's\",\n",
       "  'top-flight',\n",
       "  'kite',\n",
       "  'unconscionable',\n",
       "  'sync',\n",
       "  '144',\n",
       "  'teachings',\n",
       "  'non-titillating',\n",
       "  'full-speed',\n",
       "  'bernhard',\n",
       "  'meritorious',\n",
       "  'then-technological',\n",
       "  'infected',\n",
       "  'bounty',\n",
       "  'eh-dan',\n",
       "  '20thcentury',\n",
       "  'immensely',\n",
       "  'win-at-all-costs',\n",
       "  'shoulder',\n",
       "  'brittany',\n",
       "  'willem',\n",
       "  'southwest',\n",
       "  'hurled',\n",
       "  'competiton',\n",
       "  ...},\n",
       " {0: 0.5, 1: 0.5},\n",
       " {0: !                  0.001397\n",
       "  \"                  0.012056\n",
       "  &                  0.000139\n",
       "  (                  0.007469\n",
       "  )                  0.007591\n",
       "  ,                  0.046620\n",
       "  -                  0.000792\n",
       "  .                  0.042513\n",
       "  10/10              0.000011\n",
       "  2                  0.000254\n",
       "  20                 0.000053\n",
       "  3                  0.000137\n",
       "  4/10               0.000009\n",
       "  7/10               0.000029\n",
       "  8/10               0.000033\n",
       "  9/10               0.000012\n",
       "  :                  0.002037\n",
       "  ?                  0.002911\n",
       "  a                  0.023554\n",
       "  about              0.002381\n",
       "  accident           0.000050\n",
       "  actors             0.000472\n",
       "  actually           0.000578\n",
       "  after              0.001108\n",
       "  again              0.000427\n",
       "  ago                0.000127\n",
       "  all                0.002827\n",
       "  also               0.001012\n",
       "  although           0.000407\n",
       "  always             0.000287\n",
       "                       ...   \n",
       "  grazes             0.000001\n",
       "  north's            0.000001\n",
       "  rattle             0.000001\n",
       "  regiment's         0.000001\n",
       "  searles            0.000001\n",
       "  south--forever     0.000001\n",
       "  war--that          0.000001\n",
       "  170                0.000001\n",
       "  chief-of-stafff    0.000001\n",
       "  countrysides       0.000001\n",
       "  discharge          0.000001\n",
       "  downgrade          0.000001\n",
       "  grittiest          0.000001\n",
       "  unquestioned       0.000001\n",
       "  all-seeing         0.000001\n",
       "  cage-world         0.000001\n",
       "  capitalized        0.000001\n",
       "  glass'             0.000001\n",
       "  keyboardist        0.000001\n",
       "  obscuring          0.000001\n",
       "  obstructions       0.000001\n",
       "  overflying         0.000001\n",
       "  paneled            0.000001\n",
       "  powaqqatsi         0.000001\n",
       "  robots'            0.000001\n",
       "  snoots             0.000001\n",
       "  tangerine          0.000001\n",
       "  timbre             0.000001\n",
       "  true-man           0.000001\n",
       "  vainly             0.000001\n",
       "  Length: 50920, dtype: float64, 1: !                  0.000785\n",
       "  \"                  0.010135\n",
       "  &                  0.000117\n",
       "  (                  0.007178\n",
       "  )                  0.007208\n",
       "  ,                  0.050657\n",
       "  -                  0.000973\n",
       "  .                  0.040234\n",
       "  10/10              0.000016\n",
       "  2                  0.000204\n",
       "  20                 0.000035\n",
       "  3                  0.000099\n",
       "  4/10               0.000007\n",
       "  7/10               0.000041\n",
       "  8/10               0.000044\n",
       "  9/10               0.000021\n",
       "  :                  0.001794\n",
       "  ?                  0.001875\n",
       "  a                  0.024006\n",
       "  about              0.002051\n",
       "  accident           0.000076\n",
       "  actors             0.000391\n",
       "  actually           0.000476\n",
       "  after              0.001093\n",
       "  again              0.000430\n",
       "  ago                0.000125\n",
       "  all                0.002519\n",
       "  also               0.001433\n",
       "  although           0.000584\n",
       "  always             0.000427\n",
       "                       ...   \n",
       "  grazes             0.000002\n",
       "  north's            0.000002\n",
       "  rattle             0.000002\n",
       "  regiment's         0.000002\n",
       "  searles            0.000005\n",
       "  south--forever     0.000002\n",
       "  war--that          0.000002\n",
       "  170                0.000002\n",
       "  chief-of-stafff    0.000002\n",
       "  countrysides       0.000002\n",
       "  discharge          0.000002\n",
       "  downgrade          0.000002\n",
       "  grittiest          0.000002\n",
       "  unquestioned       0.000002\n",
       "  all-seeing         0.000002\n",
       "  cage-world         0.000002\n",
       "  capitalized        0.000002\n",
       "  glass'             0.000002\n",
       "  keyboardist        0.000002\n",
       "  obscuring          0.000002\n",
       "  obstructions       0.000002\n",
       "  overflying         0.000002\n",
       "  paneled            0.000002\n",
       "  powaqqatsi         0.000002\n",
       "  robots'            0.000002\n",
       "  snoots             0.000002\n",
       "  tangerine          0.000002\n",
       "  timbre             0.000002\n",
       "  true-man           0.000002\n",
       "  vainly             0.000002\n",
       "  Length: 50920, dtype: float64})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = NB()\n",
    "nb.fit(texts,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T17:25:02.031448Z",
     "start_time": "2018-11-28T17:24:34.572892Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "SCORE = []\n",
    "for train_index, test_index in kf.split(range(2000)):\n",
    "    X_train, X_test = [texts[i] for i in train_index], [texts[i] for i in test_index]\n",
    "    y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "    nb = NB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    SCORE.append(nb.score(X_test, y_test))\n",
    "    break\n",
    "print(np.mean(SCORE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T15:10:04.558668Z",
     "start_time": "2018-11-23T15:10:04.553842Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./34data/data/english.stop\", encoding=\"utf8\", mode=\"r+\") as f:\n",
    "    stop_words = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T17:26:00.545552Z",
     "start_time": "2018-11-28T17:26:00.538593Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_word(text):\n",
    "    words_text = text.split()\n",
    "    words_without_stop_words = [word for word in words_text if word not in stop_words]\n",
    "    unique, count = np.unique(words_without_stop_words, return_counts=True)\n",
    "    return pd.Series(dict(zip(unique, count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T17:28:24.660295Z",
     "start_time": "2018-11-28T17:26:02.609177Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8155000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "SCORE = []\n",
    "for train_index, test_index in kf.split(range(2000)):\n",
    "    X_train, X_test = [texts[i] for i in train_index], [texts[i] for i in test_index]\n",
    "    y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "    nb = NB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    SCORE.append(nb.score(X_test, y_test))\n",
    "print(np.mean(SCORE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:53:45.918136Z",
     "start_time": "2018-11-29T12:53:45.859003Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:53:55.113673Z",
     "start_time": "2018-11-29T12:53:55.109208Z"
    }
   },
   "outputs": [],
   "source": [
    "cv=CountVectorizer('content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T15:29:38.408109Z",
     "start_time": "2018-11-29T15:29:36.572552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T22:31:10.341855Z",
     "start_time": "2018-11-21T22:31:10.338778Z"
    }
   },
   "outputs": [],
   "source": [
    "cv.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:53:59.031921Z",
     "start_time": "2018-11-29T12:53:59.026391Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:54:50.756377Z",
     "start_time": "2018-11-29T12:54:50.751460Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:54:29.030010Z",
     "start_time": "2018-11-29T12:54:29.025783Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:54:46.553698Z",
     "start_time": "2018-11-29T12:54:46.550216Z"
    }
   },
   "outputs": [],
   "source": [
    "# CountVectorizer(stop_words=stop_words)\n",
    "stem_vectorizer = StemmedCountVectorizer(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:54:51.980780Z",
     "start_time": "2018-11-29T12:54:51.972553Z"
    }
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', stem_vectorizer),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T16:07:12.541672Z",
     "start_time": "2018-11-23T16:06:07.889629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "SCORE = []\n",
    "for train_index, test_index in kf.split(range(2000)):\n",
    "    X_train, X_test = [texts[i] for i in train_index], [texts[i] for i in test_index]\n",
    "    y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "    text_clf.fit(X_train, y_train) \n",
    "    SCORE.append(text_clf.score(X_test, y_test))\n",
    "print(np.mean(SCORE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:54:24.481043Z",
     "start_time": "2018-11-29T12:54:24.476896Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:54:43.858030Z",
     "start_time": "2018-11-29T12:54:43.848248Z"
    }
   },
   "outputs": [],
   "source": [
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def __init__(self, stemmer):\n",
    "        super(StemmedCountVectorizer, self).__init__()\n",
    "        self.stemmer = stemmer\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc:(self.stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T16:05:22.733931Z",
     "start_time": "2018-11-23T16:05:22.727231Z"
    }
   },
   "outputs": [],
   "source": [
    "class stemmer():\n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "    def fit(self, *args):\n",
    "        return self\n",
    "    def transform(self,words):\n",
    "        stem = SnowballStemmer(\"english\")\n",
    "        return [stem.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T15:23:33.122529Z",
     "start_time": "2018-11-23T15:23:33.119438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T15:33:24.957185Z",
     "start_time": "2018-11-23T15:33:24.953547Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_word(text):\n",
    "    words_text = text.split()\n",
    "    words_stem = [stemmer.stem(word) for word in words_text if word not in stop_words]\n",
    "    unique, count = np.unique(words_stem, return_counts=True)\n",
    "    return pd.Series(dict(zip(unique, count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:52:17.889302Z",
     "start_time": "2018-11-29T12:52:17.881006Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_word(text):\n",
    "    words_text = text.split()\n",
    "    words_f = [stemmer.stem(word) for word in words_text if (word not in stop_words) and (pos_tag([word])[0][1] in ['NN', 'ADV','VB','ADJ'])]\n",
    "    unique, count = np.unique(words_stem, return_counts=True)\n",
    "    return pd.Series(dict(zip(unique, count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:03:54.195504Z",
     "start_time": "2018-11-29T12:03:50.723972Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:35:08.036404Z",
     "start_time": "2018-11-29T12:35:08.029622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buy', 'NN'), ('you', 'PRP')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag([\"buy\", \"you\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:35:40.224783Z",
     "start_time": "2018-11-29T12:35:40.218441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 'PRP')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag([\"buy\"])\n",
    "pos_tag([\"you\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:26:49.227615Z",
     "start_time": "2018-11-29T12:26:49.224065Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T12:57:46.510950Z",
     "start_time": "2018-11-29T12:54:57.858374Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "SCORE = []\n",
    "for train_index, test_index in kf.split(range(2000)):\n",
    "    X_train, X_test = [texts[i] for i in train_index], [texts[i] for i in test_index]\n",
    "    y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "    text_clf.fit(X_train, y_train) \n",
    "    SCORE.append(text_clf.score(X_test, y_test))\n",
    "print(np.mean(SCORE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 465,
   "position": {
    "height": "487px",
    "left": "533px",
    "right": "20px",
    "top": "96px",
    "width": "558px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
