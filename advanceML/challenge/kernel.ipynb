{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34f31fb7fe56cddfd761ade7c0bee9430712341d"
   },
   "outputs": [],
   "source": [
    "train_images_fname = '../input/db_train.raw'\n",
    "train_labels_fname = '../input/label_2019_train.txt'\n",
    "\n",
    "val_images_fname    = '../input/db_val.raw'\n",
    "\n",
    "\n",
    "# number of images\n",
    "num_train_images = 116157\n",
    "num_valid_images = 27013\n",
    "\n",
    "\n",
    "# size of the images 56*56 pixels in gray levels\n",
    "image_dim = 56 * 56 * 3\n",
    "\n",
    "train_images_label = np.loadtxt(train_labels_fname, dtype=np.float64)\n",
    "\n",
    "with open(train_images_fname, 'rb') as f:\n",
    "    train_images_data = np.fromfile(f, dtype=np.uint8, count=num_train_images * image_dim).astype(np.float32)\n",
    "    train_images_data = train_images_data.reshape(num_train_images, image_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def plot_gallery(images,label, n_row=4, n_col=8, title= 'gallery'):\n",
    "    n_components = n_row * n_col\n",
    "    image_shape = (56, 56, 3)\n",
    "    images = images[:n_components]\n",
    "    \"\"\"Plot images as gallery\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.26 * n_row))\n",
    "    plt.suptitle(title, size=16)\n",
    "    for i, comp in enumerate(images):\n",
    "        ax = plt.subplot(n_row, n_col, i + 1)\n",
    "        ax.set_title(\"{}\".format(label[i]))\n",
    "        comp = comp.reshape(image_shape)\n",
    "        vmax = comp.max()\n",
    "        vmin = comp.min()\n",
    "        dmy = np.nonzero(comp < 0)\n",
    "        if len(dmy[0]) > 0:\n",
    "            yz, xz = dmy\n",
    "        comp[comp < 0] = 0\n",
    "\n",
    "        plt.imshow(comp, cmap=plt.cm.gray, vmax=vmax, vmin=vmin)\n",
    "\n",
    "        if len(dmy[0]) > 0:\n",
    "            plt.plot(xz, yz, 'r,', hold=True)\n",
    "            print(len(dmy[0]), \"negative-valued pixels\")\n",
    "\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13549cf503061fbee29308e33cd8dea68fe6143c"
   },
   "outputs": [],
   "source": [
    "# plot_gallery(train_images_data/255, train_images_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f93f1bb5c356c9abbad1e8b4badb1f9aab680455"
   },
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# n_sne = 700\n",
    "\n",
    "# tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "# tsne_results = tsne.fit_transform(train_images_data[:n_sne])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "452d953310c222aa5982539de316b1aa87f7270f"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "189047b121bd2a673000c59543c5fc44662ce6dc"
   },
   "outputs": [],
   "source": [
    "# len(tsne_results), len(train_images_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b0a77478b3f82378be8ea0d890314f6efc865e8"
   },
   "outputs": [],
   "source": [
    "# sns.scatterplot(tsne_results[:,0], tsne_results[:,1], hue=train_images_label[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e964c1102ff3ad56ee49b962f52774c3203ea2bc"
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d88f35bedd9737656a300573d618b28eca136c4"
   },
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0216ac0b31028cf623785f0e0e8317eed5cde7d2"
   },
   "outputs": [],
   "source": [
    "# tr = pca.fit_transform(train_images_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11b5fde35aca7f21d5eaceacf57988a879ddd6c4"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16,9))\n",
    "# sns.scatterplot(tr[:,0], tr[:,1], hue=train_images_label[:], alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7dd2da56e8080e6f2ca075a39bb78cde6511508"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a0c4a8bf4cc1af012af92fb1c91bb0dabc7ee98"
   },
   "outputs": [],
   "source": [
    "mv keras-vggface/keras_vggface ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "207a7b0c80db1e64cd8b81487f1da057843d9dad"
   },
   "outputs": [],
   "source": [
    "%%writefile keras_vggface/models.py\n",
    "from keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D, \\\n",
    "    GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
    "    AveragePooling2D, Reshape, Permute, multiply\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras_vggface import utils\n",
    "from keras.engine.topology import get_source_inputs\n",
    "import warnings\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights='vggface',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=2622):\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(\n",
    "        img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(\n",
    "        x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(\n",
    "        x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(\n",
    "        x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(\n",
    "        x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(\n",
    "        x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(\n",
    "        x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(\n",
    "        x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(\n",
    "        x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(\n",
    "        x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(\n",
    "        x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(\n",
    "        x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, name='fc6')(x)\n",
    "        x = Activation('relu', name='fc6/relu')(x)\n",
    "        x = Dense(4096, name='fc7')(x)\n",
    "        x = Activation('relu', name='fc7/relu')(x)\n",
    "        x = Dense(classes, name='fc8')(x)\n",
    "        x = Activation('softmax', name='fc8/softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "            # Ensure that the model takes into account\n",
    "            # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "        # Create model.\n",
    "    model = Model(inputs, x, name='vggface_vgg16')  # load weights\n",
    "    if weights == 'vggface':\n",
    "        if include_top:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_vgg16.h5',\n",
    "                                    utils.\n",
    "                                    VGG16_WEIGHTS_PATH,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        else:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_notop_vgg16.h5',\n",
    "                                    utils.VGG16_WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='pool5')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc6')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape,\n",
    "                                                              'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_identity_block(input_tensor, kernel_size, filters, stage, block,\n",
    "                          bias=False):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
    "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_increase\"\n",
    "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), use_bias=bias, name=conv1_reduce_name)(\n",
    "        input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, use_bias=bias,\n",
    "               padding='same', name=conv3_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), use_bias=bias, name=conv1_increase_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_conv_block(input_tensor, kernel_size, filters, stage, block,\n",
    "                      strides=(2, 2), bias=False):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
    "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_increase\"\n",
    "    conv1_proj_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_proj\"\n",
    "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides, use_bias=bias,\n",
    "               name=conv1_reduce_name)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same', use_bias=bias,\n",
    "               name=conv3_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides, use_bias=bias,\n",
    "                      name=conv1_proj_name)(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=conv1_proj_name + \"/bn\")(\n",
    "        shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def RESNET50(include_top=True, weights='vggface',\n",
    "             input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=8631):\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=197,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (7, 7), use_bias=False, strides=(2, 2), padding='same',\n",
    "        name='conv1/7x7_s2')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='conv1/7x7_s2/bn')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = resnet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
    "    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
    "    x = resnet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
    "\n",
    "    x = resnet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
    "    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
    "    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
    "    x = resnet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
    "\n",
    "    x = resnet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
    "    x = resnet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
    "\n",
    "    x = resnet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
    "    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
    "    x = resnet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
    "\n",
    "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, activation='softmax', name='classifier')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vggface_resnet50')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'vggface':\n",
    "        if include_top:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_resnet50.h5',\n",
    "                                    utils.RESNET50_WEIGHTS_PATH,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        else:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_notop_resnet50.h5',\n",
    "                                    utils.RESNET50_WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='avg_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='classifier')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape,\n",
    "                                                              'channels_first')\n",
    "\n",
    "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
    "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                          'are using the Theano '\n",
    "                          'image data format convention '\n",
    "                          '(`image_data_format=\"channels_first\"`). '\n",
    "                          'For best performance, set '\n",
    "                          '`image_data_format=\"channels_last\"` in '\n",
    "                          'your Keras config '\n",
    "                          'at ~/.keras/keras.json.')\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def senet_se_block(input_tensor, stage, block, compress_rate=16, bias=False):\n",
    "    conv1_down_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_down\"\n",
    "    conv1_up_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_up\"\n",
    "\n",
    "    num_channels = int(input_tensor.shape[-1])\n",
    "    bottle_neck = int(num_channels // compress_rate)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Reshape((1, 1, num_channels))(se)\n",
    "    se = Conv2D(bottle_neck, (1, 1), use_bias=bias,\n",
    "                name=conv1_down_name)(se)\n",
    "    se = Activation('relu')(se)\n",
    "    se = Conv2D(num_channels, (1, 1), use_bias=bias,\n",
    "                name=conv1_up_name)(se)\n",
    "    se = Activation('sigmoid')(se)\n",
    "\n",
    "    x = input_tensor\n",
    "    x = multiply([x, se])\n",
    "    return x\n",
    "\n",
    "\n",
    "def senet_conv_block(input_tensor, kernel_size, filters,\n",
    "                     stage, block, bias=False, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
    "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_increase\"\n",
    "    conv1_proj_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_proj\"\n",
    "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), use_bias=bias, strides=strides,\n",
    "               name=conv1_reduce_name)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same', use_bias=bias,\n",
    "               name=conv3_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
    "\n",
    "    se = senet_se_block(x, stage=stage, block=block, bias=True)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), use_bias=bias, strides=strides,\n",
    "                      name=conv1_proj_name)(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis,\n",
    "                                  name=conv1_proj_name + \"/bn\")(shortcut)\n",
    "\n",
    "    m = layers.add([se, shortcut])\n",
    "    m = Activation('relu')(m)\n",
    "    return m\n",
    "\n",
    "\n",
    "def senet_identity_block(input_tensor, kernel_size,\n",
    "                         filters, stage, block, bias=False):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv1_reduce_name = 'conv' + str(stage) + \"_\" + str(block) + \"_1x1_reduce\"\n",
    "    conv1_increase_name = 'conv' + str(stage) + \"_\" + str(\n",
    "        block) + \"_1x1_increase\"\n",
    "    conv3_name = 'conv' + str(stage) + \"_\" + str(block) + \"_3x3\"\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), use_bias=bias,\n",
    "               name=conv1_reduce_name)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_reduce_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same', use_bias=bias,\n",
    "               name=conv3_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv3_name + \"/bn\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv1_increase_name, use_bias=bias)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=conv1_increase_name + \"/bn\")(x)\n",
    "\n",
    "    se = senet_se_block(x, stage=stage, block=block, bias=True)\n",
    "\n",
    "    m = layers.add([x, se])\n",
    "    m = Activation('relu')(m)\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def SENET50(include_top=True, weights='vggface',\n",
    "            input_tensor=None, input_shape=None,\n",
    "            pooling=None,\n",
    "            classes=8631):\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=197,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (7, 7), use_bias=False, strides=(2, 2), padding='same',\n",
    "        name='conv1/7x7_s2')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='conv1/7x7_s2/bn')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = senet_conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
    "    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
    "    x = senet_identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
    "\n",
    "    x = senet_conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
    "    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
    "    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
    "    x = senet_identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
    "\n",
    "    x = senet_conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
    "    x = senet_identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
    "\n",
    "    x = senet_conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
    "    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
    "    x = senet_identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
    "\n",
    "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, activation='softmax', name='classifier')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vggface_senet50')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'vggface':\n",
    "        if include_top:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_senet50.h5',\n",
    "                                    utils.SENET50_WEIGHTS_PATH,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        else:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_notop_senet50.h5',\n",
    "                                    utils.SENET50_WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir=utils.VGGFACE_DIR)\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='avg_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='classifier')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape,\n",
    "                                                              'channels_first')\n",
    "\n",
    "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
    "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                          'are using the Theano '\n",
    "                          'image data format convention '\n",
    "                          '(`image_data_format=\"channels_first\"`). '\n",
    "                          'For best performance, set '\n",
    "                          '`image_data_format=\"channels_last\"` in '\n",
    "                          'your Keras config '\n",
    "                          'at ~/.keras/keras.json.')\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52379e09a67e8ed2995c73852d8ea023172d48ae"
   },
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "324cc345473632f2cd67f64ad6026b80f8ebe684"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense, Input, Reshape, Lambda, RepeatVector\n",
    "from keras.models import Model\n",
    "from tensorflow.image import resize_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50521ad3d0b3bee9dd942c6d6a820024e7a51992"
   },
   "outputs": [],
   "source": [
    "img_inputs = Input(shape=(56*56*3,))\n",
    "img_reshape = Reshape([56,56,3])(img_inputs)\n",
    "img_resized = Lambda(lambda x : resize_images(x,[224,224],\n",
    "    align_corners = True, # possibly important\n",
    "    preserve_aspect_ratio = True))(img_reshape)\n",
    "resize_model = Model(inputs=img_inputs, outputs=img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bff57d2cd655f2969e5598194fa4e825f901f4b4"
   },
   "outputs": [],
   "source": [
    "train_images_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c162ee3db54dae020a7f0811decc06afc95bce41"
   },
   "outputs": [],
   "source": [
    "plt.imshow(resize_model.predict(train_images_data[:1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8850e56d4b47663a3342b94efb5cc9634cb12dc1"
   },
   "outputs": [],
   "source": [
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "vgg_model = VGGFace(include_top=False, input_shape=(224, 224, 3))\n",
    "last_layer = vgg_model.get_layer('pool5').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = Dense(hidden_dim/4, activation='relu', name='fc7')(x)\n",
    "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "custom_vgg_model = Model(vgg_model.input, out)\n",
    "frozen_layer = -3\n",
    "for layer in custom_vgg_model.layers[:frozen_layer]:\n",
    "    layer.trainable = False\n",
    "for layer in custom_vgg_model.layers[frozen_layer:]:\n",
    "    layer.trainable = True\n",
    "final_model = Model(inputs = resize_model.input, outputs = custom_vgg_model(resize_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c41c0f1b9e12f5a6559cbcb159ce2a5adc79d518"
   },
   "outputs": [],
   "source": [
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "adb5ac7a8965bc5ca36260e20f9ed0dba04286be"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2bd3e2cb806324401c4950780173a90a8adfe95"
   },
   "outputs": [],
   "source": [
    "labels = to_categorical(train_images_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c120653d94888ab2a61fd9f10ecf471b8bed9b2b"
   },
   "outputs": [],
   "source": [
    "final_model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "final_model.fit(train_images_data, labels, validation_split=0.1, batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0a7db1b6820b19bd8d7d7b02a63a324b204743c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
